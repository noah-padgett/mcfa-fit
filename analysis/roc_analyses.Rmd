---
title: "ROC Analyses"
date: "2019-05-09"
output: workflowr::wflow_html
editor_options:
  chunk_output_type: console
---


Purpose of this file:

   1. Conduct ROC Analysies
   2. Create ROC Curves
   3. Create Summary tables of ROC analyses

# Packages and Set-Up

```{r set-up, tidy=T}
##Chunk iptions
knitr::opts_chunk$set(out.width="225%")

#setwd('C:/Users/noahp/Dropbox/MCFA Thesis/Code Results')

## Packages
## General Packages
library(tidyverse)
library(car)
library(psych)
# Formatting and Tables
library(kableExtra)
library(xtable)
# For plotting
library(ggplot2)
theme_set(theme_bw())
# Data manipulating
library(dplyr)
# ROC Analysis
library(pROC)

## One global parameter for printing figures
save.fig <- F

## Load up the functions needed for ANOVA and Assumption checking
source('code/r_functions.R')

```


# Data Management

```{r data, tidy=T}

sim_results <- as_tibble(read.table('data/compiled_fit_results.txt', header=T,sep='\t'))

## Next, turn condition into a factor for plotting
sim_results$Condition <- as.factor(sim_results$Condition)

## Next, since TLI is non-normed, any value greater than 1 needs to be rescaled to 1.
sim_results$TLI <- ifelse(sim_results$TLI > 1, 1, sim_results$TLI)
sim_results$TLI <- ifelse(sim_results$TLI < 0, 0, sim_results$TLI)
## Next, summarize the results of the chi-square test of model fit. This is done simply by comparing the p-value to alpha (0.05) and indicating whether the model was flagged as fitting or not.
# Note: if  p < 0.05 then this variable is flagged as 0, and 1 otherwise
sim_results$Chi2_pvalue_decision <- ifelse(sim_results$chisqu_pvalue > 0.05, 1, 0)
# 0 = rejected that these data fit this model
# 1 = failed to reject that these data fit this model

```

## Adding Labels to Conditions

Currently, each condition is kind of like a hidden id that we don't know what the actual factor is. 
So, first thing isto create meaningful labels for us to use.
Remember, the 72 conditions for the this study were

  1. Level-1 sample size (5, 10, 30)
  2. Level-2 sample size (30, 50, 100, 200)
  3. Observed indicator ICC (.1, .3, .5)
  4. Latent variable ICC (.1, .5)
  
```{r}
## level-1 Sample size
ss_l1 <- c(5, 10, 30) ## 6 conditions each
ss_l2 <- c(30, 50, 100, 200) ## 18 condition each
icc_ov <- c(.1, .3, .5) ## 2 conditions each
icc_lv <- c(.1, .5) ## every other condition
nCon <- 72 # number of conditions
nRep <- 500 # number of replications per condition
nMod <- 12 ## numberof estimated models per conditions
## Total number of rows: 432,000
ss_l2 <- c(rep(ss_l2[1], 18*nRep*nMod), rep(ss_l2[2], 18*nRep*nMod), rep(ss_l2[3], 18*nRep*nMod), rep(ss_l2[4], 18*nRep*nMod))
ss_l1 <- rep(c(rep(ss_l1[1],6*nRep*nMod), rep(ss_l1[2],6*nRep*nMod), rep(ss_l1[3],6*nRep*nMod)), 4)
icc_ov <- rep(c(rep(icc_ov[1], 2*nRep*nMod), rep(icc_ov[2], 2*nRep*nMod), rep(icc_ov[3], 2*nRep*nMod)), 12)
icc_lv <- rep(c(rep(icc_lv[1], nRep*nMod), rep(icc_lv[2], nRep*nMod)), 36)
## Force these vectors to be column vectors
ss_l1 <- matrix(ss_l1, ncol=1)
ss_l2 <- matrix(ss_l2, ncol=1)
icc_ov <- matrix(icc_ov, ncol=1)
icc_lv <- matrix(icc_lv, ncol=1)
## Add the labels to the results data frame
sim_results <- sim_results[order(sim_results$Condition),]
sim_results <- cbind(sim_results, ss_l1, ss_l2, icc_ov, icc_lv)

## Force the conditions to be factors
sim_results$ss_l1 <- as.factor(sim_results$ss_l1)
sim_results$ss_l2 <- as.factor(sim_results$ss_l2)
sim_results$icc_ov <- as.factor(sim_results$icc_ov)
sim_results$icc_lv <- as.factor(sim_results$icc_lv)
sim_results$Model <- factor(sim_results$Model, levels = c('C','M1','M2','M12'), ordered = T)

```

## ROC Analysis Labels

Make coding of variables/model specifications for the ROC analyses.
The coding of the variables is in order to get the correct specifications labeled for the ROC analyses to come. 
The coding is as follows:

1. C = correct model specification versus any misspecification (Model C vs. M1, M2, M12)
2. CvM1 = when only the level-1 model is misspecified (Model C vs. M1)
2. CvM2 = when only the level-2 model is misspecified (Model C vs. M2)

```{r}

## Need to make codes for the ROC analyses outcomes
# first, C vs. M1,M2,M12 - Perfect specification
sim_results$C <- ifelse(sim_results$Model == 'C', 1, 0)
table(sim_results$C)
# second, C vs. M1|M12- correct level 1 model
sim_results$CvM1 <- ifelse(sim_results$Model == 'C', 1, 0)
sim_results$CvM1[sim_results$Model == "M2" | sim_results$Model == "M12"] <- NA
table(sim_results$CvM1)
# third, C vs. M2|M12- correct level 2 model
sim_results$CvM2 <- ifelse(sim_results$Model == 'C', 1, 0)
sim_results$CvM2[sim_results$Model == "M1" | sim_results$Model == "M12"] <- NA
table(sim_results$CvM2)
```

# Introduction to ROC Analysis

ROC stands for Receiver Operating Characteristic.
ROC analysis aims to detect the presense of signals in data by looking at how the ability to classify an outcome (usually binary) based on a continuous or ordinal indicator.
ROC analyses was orginally used in wartime to help detect the presence of radar signals.
However, now ROC analysis is used in many areas including medical and psychology research.
It is commonly used as a tool to help make decisions about what tools or methods help classify objects or individuals into specific groups.

In R, a package called pROC (Robin et al., 2011) was built that greatly enhancing the flexibility of using R for ROC analysis.
For example, aside from just being able to conduct ROC analysis, one can compute confidences for this curve and conduct specific statistical tests comparing AUCs from the same data.

For the ROC analyses, we conducted them in pieces to build more and more fine grained information about the classification quality of fit indices for detecting a simple type of misspecification.
For misspecification, we broke up the ROC analyses into three major chunks.

  1. Detecting any type of misspecification (i.e., C vs. M1-M2-M12),
  2. Detecting misspecified level-1 model (i.e., C vs. M1), and
  3. Detecting misspecified level-2 model (i.e., C vs. M2).

Within each of these major chunks of analyses, we furhter investigated whether classification of correctly specified models was depended upon estimator, level-1 sample size, or level-2 sample size.
There are intitally be MANY ROC curve figures and over 1200 ROC analyses. 


Setting up the objects to store the individual results so that we can use them all for the figures.
First, we run over each condition separately then go into the conditional ROC analyses.

```{r}

fit_roc <- fit_roc_smooth <- list()
roc_summary <- as.data.frame(matrix(0,ncol=13, nrow=5*3*4*4*5))
colnames(roc_summary) <- c('Classification','Index', 'Estimator', 'Level-2 SS', 
                           'Level-1 SS', 'AUC',
                           'partial-AUC','Smoothed-AUC', 'Optimal-Threshold',
                           'Specificity','Sensitivity', 'Num-C', 'Num-Mis')
roc_summary_gen <- as.data.frame(matrix(0,ncol=8, nrow=5)*3)
colnames(roc_summary_gen) <- c('Classification','Index', 'AUC',
                           'partial-AUC','Smoothed-AUC', 'Optimal-Threshold',
                           'Specificity','Sensitivity')
# Defining iterators
CLASS <- c('C', 'CvM1','CvM2')
INDEX <- c('CFI', 'TLI', 'RMSEA', 'SRMRW', 'SRMRB')
EST <- c('ALL','MLR', 'ULSMV', 'WLSMV')
SS_L1 <- c('ALL', 5, 10, 30)
SS_L2 <- c('ALL', 30, 50, 100, 200)


## Subset to the usable cases
sim_results <- filter(sim_results, Converge == 1 & Admissible == 1)
```

## Detecting any type of misspecification

### General overview over all conditions

```{r roc-any-gen}

ig <- 1 ## counter for roc_summary
j <- 1 ## Which class?
for(index in INDEX){

    ## Print out which iteration so we know what we am looking at
    cat('\n\nROC Analysis in')
    cat('\nIndex:\t', index)
    cat('\nClassification:\t', CLASS[j])
    ## Set up iteration key
    key <- paste0(index,'.',CLASS[j])
    ## Create formula
    model <- as.formula(paste0(CLASS[j], '~', index))
    ## Fit ROC curve
    fit_roc[[key]] <-  roc(model, data=sim_results,
                           plot =TRUE, ci=TRUE, print.auc=TRUE)
    ## Create a plot of "smoothed" curve for plotting
    fit_roc_smooth[[key]] <-  smooth(roc(model, data=sim_results))
    ## Compute partial AUC for specificity .8-1
    p.auc <- auc(fit_roc[[key]], partial.auc = c(1,.8),
                 partial.auc.focus = 'sp', partial.auc.correct = T)
    ## get summary info
    roc_summary_gen[ig, 2] <- index
    roc_summary_gen[ig, 1] <- CLASS[j]
    roc_summary_gen[ig, 3] <- fit_roc[[key]]$auc ## total AUC
    roc_summary_gen[ig, 4] <- p.auc ## corrected partial AUC (.5 is no discrimination)
    roc_summary_gen[ig, 5] <- fit_roc_smooth[[key]]$auc ## smoothed AUC
    roc_summary_gen[ig, 6:8] <- coords(fit_roc[[key]], "best", 
                                   ret=c("threshold", "specificity", 'sensitivity'))
    ## print summary
    cat('\n\nSummary of ROC:\n')
    print(roc_summary_gen[ig, ])
    ## add to summary iterator
    ig <- ig + 1
} ## End loop round index

kable(roc_summary_gen[1:5,], format = 'html', digits=3) %>%
  kable_styling(full_width = T)

print(xtable(roc_summary_gen[1:5,c(2:3,6:8)], digits = 3), booktabs=T,include.rownames = F)

```

### More fine grained information within/across conditions

```{r roc-any}


i <- 1 ## counter for roc_summary
j <- 1 ## Which class?
for(index in INDEX){
  for(est in EST){
    for(s2 in SS_L2){
      for(s1 in SS_L1){

    ## Print out which iteration so we know what we are looking at
    cat('\n\nROC Analysis in')
    cat('\nIndex:\t', index)
    cat('\nClassification:\t', CLASS[j])
    cat('\nEstimation Method:\t', est)
    cat('\nLevel-2 Sample Size:\t', s2)
    cat('\nLevel-1 Sample Size:\t', s1)
    ## Set up iteration key
    key <- paste0(index,'.',CLASS[j],'.',est,'.', s2,'.',s1)
    # Subset data as  needed
    if(est == 'ALL' & s2 == 'ALL' & s1 == 'ALL') mydata <- sim_results

    if(est != 'ALL' & s2 == 'ALL' & s1 == 'ALL'){
      mydata <- filter(sim_results, Estimator == est)
    }
    if(est == 'ALL' & s2 != 'ALL' & s1 == 'ALL'){
      mydata <- filter(sim_results, ss_l2 == s2)
    }
    if(est == 'ALL' & s2 == 'ALL' & s1 != 'ALL'){
      mydata <- filter(sim_results, ss_l1 == s1)
    }
    if(est != 'ALL' & s2 != 'ALL' & s1 == 'ALL'){
      mydata <- filter(sim_results, Estimator == est, ss_l2 == s2)
    }
    if(est != 'ALL' & s2 == 'ALL' & s1 != 'ALL'){
      mydata <- filter(sim_results, Estimator == est, ss_l1 == s1)
    }
    if(est == 'ALL' & s2 != 'ALL' & s1 != 'ALL'){
      mydata <- filter(sim_results, ss_l2 == s2, ss_l1 == s1)
    }
    if(est != 'ALL' & s2 != 'ALL' & s1 != 'ALL'){
      mydata <- filter(sim_results, Estimator == est, ss_l2 == s2, ss_l1 == s1)
    }
    ## Create formula
    model <- as.formula(paste0(CLASS[j], '~', index))
    ## Fit ROC curve
    fit_roc[[key]] <-  roc(model, data=mydata,
                           plot =TRUE, ci=TRUE, print.auc=TRUE)
    ## Create a plot of "smoothed" curve for plotting
    fit_roc_smooth[[key]] <-  smooth(roc(model, data=mydata))
    ## Compute partial AUC for specificity .8-1
    p.auc <- auc(fit_roc[[key]], partial.auc = c(1,.8),
                 partial.auc.focus = 'sp', partial.auc.correct = T)
    ## get summary info
    roc_summary[i, 2] <- index
    roc_summary[i, 1] <- CLASS[j]
    roc_summary[i, 3] <- est ##estimator
    roc_summary[i, 4] <- s2 ## level-2 sample size
    roc_summary[i, 5] <- s1 ## level-1 sample size
    roc_summary[i, 6] <- fit_roc[[key]]$auc ## total AUC
    roc_summary[i, 7] <- p.auc ## corrected partial AUC (.5 is no discrimination)
    roc_summary[i, 8] <- fit_roc_smooth[[key]]$auc ## smoothed AUC
    roc_summary[i, 9:11] <- coords(fit_roc[[key]], "best", 
                                   ret=c("threshold", "specificity", 'sensitivity'))
    
    ## add number of C and number of miss models in analysis
    n.C <- nrow(mydata[ mydata[, CLASS[j]] == 1, ])
    n.M <- nrow(mydata[ mydata[, CLASS[j]] == 0, ])
    roc_summary[i, 12] <- n.C
    roc_summary[i, 13] <- n.M
    
    ## print summary
    cat('\n\nSummary of ROC:\n')
    print(roc_summary[i, ])
    ## add to summary iterator
    i <- i + 1
      } ## end loop around ss l1
    } ## End loop around ss l2
  } ## End loop around estimator
} ## End loop round index

kable(roc_summary[1:400, ], format = 'html', digits=3) %>%
  kable_styling(full_width = T)

```

## Detecting Misspecification at Level-1

### General overview over all conditions

```{r roc-l1-gen}

j <- 2 ## Which class?
for(index in INDEX){

    ## Print out which iteration so we know what we am looking at
    cat('\n\nROC Analysis in')
    cat('\nIndex:\t', index)
    cat('\nClassification:\t', CLASS[j])
    ## Set up iteration key
    key <- paste0(index,'.',CLASS[j])
    ## Create formula
    model <- as.formula(paste0(CLASS[j], '~', index))
    ## Fit ROC curve
    fit_roc[[key]] <-  roc(model, data=sim_results,
                           plot =TRUE, ci=TRUE, print.auc=TRUE)
    ## Create a plot of "smoothed" curve for plotting
    fit_roc_smooth[[key]] <-  smooth(roc(model, data=sim_results))
    ## Compute partial AUC for specificity .8-1
    p.auc <- auc(fit_roc[[key]], partial.auc = c(1,.8),
                 partial.auc.focus = 'sp', partial.auc.correct = T)
    ## get summary info
    roc_summary_gen[ig, 2] <- index
    roc_summary_gen[ig, 1] <- CLASS[j]
    roc_summary_gen[ig, 3] <- fit_roc[[key]]$auc ## total AUC
    roc_summary_gen[ig, 4] <- p.auc ## corrected partial AUC (.5 is no discrimination)
    roc_summary_gen[ig, 5] <- fit_roc_smooth[[key]]$auc ## smoothed AUC
    roc_summary_gen[ig, 6:8] <- coords(fit_roc[[key]], "best", 
                                   ret=c("threshold", "specificity", 'sensitivity'))
    ## print summary
    cat('\n\nSummary of ROC:\n')
    print(roc_summary_gen[ig, ])
    ## add to summary iterator
    ig <- ig + 1
} ## End loop round index

kable(roc_summary_gen[1:5,], format = 'html', digits=3) %>%
  kable_styling(full_width = T)

print(xtable(roc_summary_gen[1:5,c(2:3,6:8)], digits = 3), booktabs=T,include.rownames = F)

```

### More fine grained information within/across conditions

```{r roc-l1}

j <- 2 ## Which class?
for(index in INDEX){
  for(est in EST){
    for(s2 in SS_L2){
      for(s1 in SS_L1){

    ## Print out which iteration so we know what we are looking at
    cat('\n\nROC Analysis in')
    cat('\nIndex:\t', index)
    cat('\nClassification:\t', CLASS[j])
    cat('\nEstimation Method:\t', est)
    cat('\nLevel-2 Sample Size:\t', s2)
    cat('\nLevel-1 Sample Size:\t', s1)
    ## Set up iteration key
    key <- paste0(index,'.',CLASS[j],'.',est,'.', s2,'.',s1)
    # Subset data as  needed
    if(est == 'ALL' & s2 == 'ALL' & s1 == 'ALL') mydata <- sim_results

    if(est != 'ALL' & s2 == 'ALL' & s1 == 'ALL'){
      mydata <- filter(sim_results, Estimator == est)
    }
    if(est == 'ALL' & s2 != 'ALL' & s1 == 'ALL'){
      mydata <- filter(sim_results, ss_l2 == s2)
    }
    if(est == 'ALL' & s2 == 'ALL' & s1 != 'ALL'){
      mydata <- filter(sim_results, ss_l1 == s1)
    }
    if(est != 'ALL' & s2 != 'ALL' & s1 == 'ALL'){
      mydata <- filter(sim_results, Estimator == est, ss_l2 == s2)
    }
    if(est != 'ALL' & s2 == 'ALL' & s1 != 'ALL'){
      mydata <- filter(sim_results, Estimator == est, ss_l1 == s1)
    }
    if(est == 'ALL' & s2 != 'ALL' & s1 != 'ALL'){
      mydata <- filter(sim_results, ss_l2 == s2, ss_l1 == s1)
    }
    if(est != 'ALL' & s2 != 'ALL' & s1 != 'ALL'){
      mydata <- filter(sim_results, Estimator == est, ss_l2 == s2, ss_l1 == s1)
    }
    ## Create formula
    model <- as.formula(paste0(CLASS[j], '~', index))
    ## Fit ROC curve
    fit_roc[[key]] <-  roc(model, data=mydata,
                           plot =TRUE, ci=TRUE, print.auc=TRUE)
    ## Create a plot of "smoothed" curve for plotting
    fit_roc_smooth[[key]] <-  smooth(roc(model, data=mydata))
    ## Compute partial AUC for specificity .8-1
    p.auc <- auc(fit_roc[[key]], partial.auc = c(1,.8),
                 partial.auc.focus = 'sp', partial.auc.correct = T)
    ## get summary info
    roc_summary[i, 2] <- index
    roc_summary[i, 1] <- CLASS[j]
    roc_summary[i, 3] <- est ##estimator
    roc_summary[i, 4] <- s2 ## level-2 sample size
    roc_summary[i, 5] <- s1 ## level-1 sample size
    roc_summary[i, 6] <- fit_roc[[key]]$auc ## total AUC
    roc_summary[i, 7] <- p.auc ## corrected partial AUC (.5 is no discrimination)
    roc_summary[i, 8] <- fit_roc_smooth[[key]]$auc ## smoothed AUC
    roc_summary[i, 9:11] <- coords(fit_roc[[key]], "best", 
                                   ret=c("threshold", "specificity", 'sensitivity'))
    
    ## add number of C and number of miss models in analysis
    n.C <- nrow(mydata[ mydata[, CLASS[j]] == 1, ])
    n.M <- nrow(mydata[ mydata[, CLASS[j]] == 0, ])
    roc_summary[i, 12] <- n.C
    roc_summary[i, 13] <- n.M
    
    ## print summary
    cat('\n\nSummary of ROC:\n')
    print(roc_summary[i, ])
    ## add to summary iterator
    i <- i + 1
      } ## end loop around ss l1
    } ## End loop around ss l2
  } ## End loop around estimator
} ## End loop round index

kable(roc_summary[401:800, ], format = 'html', digits=3) %>%
  kable_styling(full_width = T)

```



## Detecting Misspecification at Level-2

### General overview over all conditions

```{r roc-l2-gen}

j <- 3 ## Which class?
for(index in INDEX){

    ## Print out which iteration so we know what we am looking at
    cat('\n\nROC Analysis in')
    cat('\nIndex:\t', index)
    cat('\nClassification:\t', CLASS[j])
    ## Set up iteration key
    key <- paste0(index,'.',CLASS[j])
    ## Create formula
    model <- as.formula(paste0(CLASS[j], '~', index))
    ## Fit ROC curve
    fit_roc[[key]] <-  roc(model, data=sim_results,
                           plot =TRUE, ci=TRUE, print.auc=TRUE)
    ## Create a plot of "smoothed" curve for plotting
    fit_roc_smooth[[key]] <-  smooth(roc(model, data=sim_results))
    ## Compute partial AUC for specificity .8-1
    p.auc <- auc(fit_roc[[key]], partial.auc = c(1,.8),
                 partial.auc.focus = 'sp', partial.auc.correct = T)
    ## get summary info
    roc_summary_gen[ig, 2] <- index
    roc_summary_gen[ig, 1] <- CLASS[j]
    roc_summary_gen[ig, 3] <- fit_roc[[key]]$auc ## total AUC
    roc_summary_gen[ig, 4] <- p.auc ## corrected partial AUC (.5 is no discrimination)
    roc_summary_gen[ig, 5] <- fit_roc_smooth[[key]]$auc ## smoothed AUC
    roc_summary_gen[ig, 6:8] <- coords(fit_roc[[key]], "best", 
                                   ret=c("threshold", "specificity", 'sensitivity'))
    ## print summary
    cat('\n\nSummary of ROC:\n')
    print(roc_summary_gen[ig, ])
    ## add to summary iterator
    ig <- ig + 1
} ## End loop round index

kable(roc_summary_gen[11:15,], format = 'html', digits=3) %>%
  kable_styling(full_width = T)

print(xtable(roc_summary_gen[11:15,c(2:3,6:8)], digits = 3), booktabs=T,include.rownames = F)

```

### More fine grained information within/across conditions

```{r roc-l2}

j <- 3 ## Which class?
for(index in INDEX){
  for(est in EST){
    for(s2 in SS_L2){
      for(s1 in SS_L1){

    ## Print out which iteration so we know what we are looking at
    cat('\n\nROC Analysis in')
    cat('\nIndex:\t', index)
    cat('\nClassification:\t', CLASS[j])
    cat('\nEstimation Method:\t', est)
    cat('\nLevel-2 Sample Size:\t', s2)
    cat('\nLevel-1 Sample Size:\t', s1)
    ## Set up iteration key
    key <- paste0(index,'.',CLASS[j],'.',est,'.', s2,'.',s1)
    # Subset data as  needed
    if(est == 'ALL' & s2 == 'ALL' & s1 == 'ALL') mydata <- sim_results

    if(est != 'ALL' & s2 == 'ALL' & s1 == 'ALL'){
      mydata <- filter(sim_results, Estimator == est)
    }
    if(est == 'ALL' & s2 != 'ALL' & s1 == 'ALL'){
      mydata <- filter(sim_results, ss_l2 == s2)
    }
    if(est == 'ALL' & s2 == 'ALL' & s1 != 'ALL'){
      mydata <- filter(sim_results, ss_l1 == s1)
    }
    if(est != 'ALL' & s2 != 'ALL' & s1 == 'ALL'){
      mydata <- filter(sim_results, Estimator == est, ss_l2 == s2)
    }
    if(est != 'ALL' & s2 == 'ALL' & s1 != 'ALL'){
      mydata <- filter(sim_results, Estimator == est, ss_l1 == s1)
    }
    if(est == 'ALL' & s2 != 'ALL' & s1 != 'ALL'){
      mydata <- filter(sim_results, ss_l2 == s2, ss_l1 == s1)
    }
    if(est != 'ALL' & s2 != 'ALL' & s1 != 'ALL'){
      mydata <- filter(sim_results, Estimator == est, ss_l2 == s2, ss_l1 == s1)
    }
    ## Create formula
    model <- as.formula(paste0(CLASS[j], '~', index))
    ## Fit ROC curve
    fit_roc[[key]] <-  roc(model, data=mydata,
                           plot =TRUE, ci=TRUE, print.auc=TRUE)
    ## Create a plot of "smoothed" curve for plotting
    fit_roc_smooth[[key]] <-  smooth(roc(model, data=mydata))
    ## Compute partial AUC for specificity .8-1
    p.auc <- auc(fit_roc[[key]], partial.auc = c(1,.8),
                 partial.auc.focus = 'sp', partial.auc.correct = T)
    ## get summary info
    roc_summary[i, 2] <- index
    roc_summary[i, 1] <- CLASS[j]
    roc_summary[i, 3] <- est ##estimator
    roc_summary[i, 4] <- s2 ## level-2 sample size
    roc_summary[i, 5] <- s1 ## level-1 sample size
    roc_summary[i, 6] <- fit_roc[[key]]$auc ## total AUC
    roc_summary[i, 7] <- p.auc ## corrected partial AUC (.5 is no discrimination)
    roc_summary[i, 8] <- fit_roc_smooth[[key]]$auc ## smoothed AUC
    roc_summary[i, 9:11] <- coords(fit_roc[[key]], "best", 
                                   ret=c("threshold", "specificity", 'sensitivity'))
    
    ## add number of C and number of miss models in analysis
    n.C <- nrow(mydata[ mydata[, CLASS[j]] == 1, ])
    n.M <- nrow(mydata[ mydata[, CLASS[j]] == 0, ])
    roc_summary[i, 12] <- n.C
    roc_summary[i, 13] <- n.M
    
    ## print summary
    cat('\n\nSummary of ROC:\n')
    print(roc_summary[i, ])
    ## add to summary iterator
    i <- i + 1
      } ## end loop around ss l1
    } ## End loop around ss l2
  } ## End loop around estimator
} ## End loop round index

kable(roc_summary[801:1200, ], format = 'html', digits=3) %>%
  kable_styling(full_width = T)

```

## Summarizing the Results

```{r roc-summary}
## SMALL summary table for the conditions of "all" estiamtors" and completely correct spec.

roc_sum_C_all <- filter(roc_summary, Estimator == "ALL", Classification == "C")
kable(roc_sum_C_all, format = 'html', row.names = F) %>%
  kable_styling(full_width = T)

print(xtable(roc_sum_C_all[,c(2,4:5,7:9)], digits = 3), booktabs=T,include.rownames = F)


## FULL Summary table

kable(roc_summary, format = 'html') %>%
  kable_styling(full_width = T)

print(xtable(roc_summary[,1:9], digits = 3), booktabs=T,include.rownames = F)

```

## Combined Figures

### First extract the data
```{r roc-data-extract}
roc_smooth_data <- as.data.frame(matrix(0,ncol=6, nrow=514*60))
colnames(roc_smooth_data) <- c('Index', 'Classification', 'Estimator', 'AUC', 'Sensitivity', 'Specificity')
CLASS <- c('C', 'C_Level_1','C_Level_2')
i <- 1
j <- 514
for(index in INDEX){
  for(est in EST){
    for(class in CLASS){
      key <- paste0(index,'.',class,'.',est)
      ## update extracted data
      roc_smooth_data[i:j, 1] <- index
      roc_smooth_data[i:j, 2] <- class
      roc_smooth_data[i:j, 3] <- est
      ## extract smooth fit object
      fit <- fit_roc_smooth[[key]]
      ## update sen,spec, and auc
      roc_smooth_data[i:j, 4] <- fit$auc
      roc_smooth_data[i:j, 5] <- fit$sensitivities
      roc_smooth_data[i:j, 6] <- fit$specificities
      ## update iterators
      i <- i + 514
      j <- j + 514
    }
  }
}


## Forcing factor orders
roc_smooth_data$Index <- factor(
  roc_smooth_data$Index, ordered = T,
  levels=c('CFI', 'TLI', 'RMSEA', 'SRMRW', 'SRMRB'))
roc_smooth_data$Classification <- factor(
  roc_smooth_data$Classification,
  levels=c('C','C_Level_1','C_Level_2'),
  labels=c('Correct', 'Correct Level-1', 'Correct Level-2'),
  ordered = T
)
# roc_smooth_data$Classification <- factor(
#   roc_smooth_data$Classification,
#   levels=c('C','C_L1_n','C_L2_n'),
#   labels=c('Correct', 'Correct Level-1', 'Correct Level-2'),
#   ordered = T
# )
```


### Plot figures

```{r figures}

p <- ggplot(roc_smooth_data, aes(x = Specificity, y=Sensitivity, group = Index)) +
  geom_line(aes(linetype=Index, color=Index))+
  facet_grid(Estimator~Classification) +
  scale_x_reverse() +
  scale_color_brewer(palette="Set1") +
  guides(color=guide_legend(title="Fit Statistics"),
         linetype=guide_legend(title="Fit Statistics"))

p
if(save.fig == T) ggsave('roc_full_plot.pdf', plot = p, height = 6,width = 9,units = 'in')

```

### Subfigures

#### Figures by Classification Outcome

```{r subfigs-class}

subdata <- filter(roc_smooth_data, Estimator == "ALL")
p <- ggplot(subdata, aes(x = Specificity, y=Sensitivity, group = Index)) +
  geom_line(aes(linetype=Index, color=Index))+
  facet_grid(.~Classification) +
  scale_x_reverse() +
  scale_color_brewer(palette="Set1") +
  guides(color=guide_legend(title="Fit Statistics"),
         linetype=guide_legend(title="Fit Statistics"))
p
if(save.fig == T) ggsave('roc_class_all.pdf', plot = p, height = 4,width = 9,units = 'in')



subdata <- filter(roc_smooth_data, Estimator == "MLR")
p <- ggplot(subdata, aes(x = Specificity, y=Sensitivity, group = Index)) +
  geom_line(aes(linetype=Index, color=Index))+
  facet_grid(.~Classification) +
  scale_x_reverse() +
  scale_color_brewer(palette="Set1") +
  guides(color=guide_legend(title="Fit Statistics"),
         linetype=guide_legend(title="Fit Statistics"))
p
if(save.fig == T) ggsave('roc_class_mlr.pdf', plot = p, height = 4,width = 9,units = 'in')



subdata <- filter(roc_smooth_data, Estimator == "ULSMV")
p <- ggplot(subdata, aes(x = Specificity, y=Sensitivity, group = Index)) +
  geom_line(aes(linetype=Index, color=Index))+
  facet_grid(.~Classification) +
  scale_x_reverse() +
  scale_color_brewer(palette="Set1") +
  guides(color=guide_legend(title="Fit Statistics"),
         linetype=guide_legend(title="Fit Statistics"))
p
if(save.fig == T) ggsave('roc_class_ulsmv.pdf', plot = p, height = 4,width = 9,units = 'in')


subdata <- filter(roc_smooth_data, Estimator == "WLSMV")
p <- ggplot(subdata, aes(x = Specificity, y=Sensitivity, group = Index)) +
  geom_line(aes(linetype=Index, color=Index))+
  facet_grid(.~Classification) +
  scale_x_reverse() +
  scale_color_brewer(palette="Set1") +
  guides(color=guide_legend(title="Fit Statistics"),
         linetype=guide_legend(title="Fit Statistics"))
p
if(save.fig == T) ggsave('roc_class_wlsmv.pdf', plot = p, height = 4,width = 9,units = 'in')
```


#### Figures by Estimator

```{r subfigs-est}

subdata <- filter(roc_smooth_data, Classification == "Correct")
p <- ggplot(subdata, aes(x = Specificity, y=Sensitivity, group = Index)) +
  geom_line(aes(linetype=Index, color=Index))+
  facet_grid(.~Estimator) +
  scale_x_reverse() +
  scale_color_brewer(palette="Set1") +
  guides(color=guide_legend(title="Fit Statistics"),
         linetype=guide_legend(title="Fit Statistics"))
p
if(save.fig == T) ggsave('roc_est_c.pdf', plot = p, height = 4,width = 9,units = 'in')



subdata <- filter(roc_smooth_data, Classification == "Correct Level-1")
p <- ggplot(subdata, aes(x = Specificity, y=Sensitivity, group = Index)) +
  geom_line(aes(linetype=Index, color=Index))+
  facet_grid(.~Estimator) +
  scale_x_reverse() +
  scale_color_brewer(palette="Set1") +
  guides(color=guide_legend(title="Fit Statistics"),
         linetype=guide_legend(title="Fit Statistics"))
p
if(save.fig == T) ggsave('roc_est_cl1.pdf', plot = p, height = 4,width = 9,units = 'in')



subdata <- filter(roc_smooth_data, Classification == "Correct Level-2")
p <- ggplot(subdata, aes(x = Specificity, y=Sensitivity, group = Index)) +
  geom_line(aes(linetype=Index, color=Index))+
  facet_grid(.~Estimator) +
  scale_x_reverse() +
  scale_color_brewer(palette="Set1") +
  guides(color=guide_legend(title="Fit Statistics"),
         linetype=guide_legend(title="Fit Statistics"))
p
if(save.fig == T) ggsave('roc_est_cl2.pdf', plot = p, height = 4,width = 9,units = 'in')


```

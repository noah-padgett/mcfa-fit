---
title: "ROC Analyses"
date: "2019-05-09"
output: workflowr::wflow_html
editor_options:
  chunk_output_type: console
---


Purpose of this file:

   1. Conduct ROC Analysies
   2. Create ROC Curves
   3. Create Summary tables of ROC analyses

# Packages and Set-Up

```{r set-up, tidy=T}
##Chunk iptions
knitr::opts_chunk$set(out.width="225%")
#setwd('C:/Users/noahp/Dropbox/MCFA Thesis/Code Results')
## Packages
## General Packages
library(tidyverse)
library(car)
library(psych)
# Formatting and Tables
library(kableExtra)
library(xtable)
# For plotting
library(ggplot2)
theme_set(theme_bw() + theme(legend.position = 'bottom'))
# Data manipulating
library(dplyr)
# ROC Analysis
library(pROC)
## One global parameter for printing figures
save.fig <- F
## Load up the functions needed for ANOVA and Assumption checking
source('code/r_functions.R')
```


# Data Management

```{r data, tidy=T}
sim_results <- as_tibble(read.table('data/compiled_fit_results.txt', header=T,sep='\t'))
## Next, turn condition into a factor for plotting
sim_results$Condition <- as.factor(sim_results$Condition)
## Next, since TLI is non-normed, any value greater than 1 needs to be rescaled to 1.
sim_results$TLI <- ifelse(sim_results$TLI > 1, 1, sim_results$TLI)
sim_results$TLI <- ifelse(sim_results$TLI < 0, 0, sim_results$TLI)
## Next, summarize the results of the chi-square test of model fit. This is done simply by comparing the p-value to alpha (0.05) and indicating whether the model was flagged as fitting or not.
# Note: if  p < 0.05 then this variable is flagged as 0, and 1 otherwise
sim_results$Chi2_pvalue_decision <- ifelse(sim_results$chisqu_pvalue > 0.05, 1, 0)
# 0 = rejected that these data fit this model
# 1 = failed to reject that these data fit this model
```

## Adding Labels to Conditions

Currently, each condition is kind of like a hidden id that we don't know what the actual factor is. 
So, first thing isto create meaningful labels for us to use.
Remember, the 72 conditions for the this study were

  1. Level-1 sample size (5, 10, 30)
  2. Level-2 sample size (30, 50, 100, 200)
  3. Observed indicator ICC (.1, .3, .5)
  4. Latent variable ICC (.1, .5)
  
```{r}
## level-1 Sample size
ss_l1 <- c(5, 10, 30) ## 6 conditions each
ss_l2 <- c(30, 50, 100, 200) ## 18 condition each
icc_ov <- c(.1, .3, .5) ## 2 conditions each
icc_lv <- c(.1, .5) ## every other condition
nCon <- 72 # number of conditions
nRep <- 500 # number of replications per condition
nMod <- 12 ## numberof estimated models per conditions
## Total number of rows: 432,000
ss_l2 <- c(rep(ss_l2[1], 18*nRep*nMod), rep(ss_l2[2], 18*nRep*nMod), rep(ss_l2[3], 18*nRep*nMod), rep(ss_l2[4], 18*nRep*nMod))
ss_l1 <- rep(c(rep(ss_l1[1],6*nRep*nMod), rep(ss_l1[2],6*nRep*nMod), rep(ss_l1[3],6*nRep*nMod)), 4)
icc_ov <- rep(c(rep(icc_ov[1], 2*nRep*nMod), rep(icc_ov[2], 2*nRep*nMod), rep(icc_ov[3], 2*nRep*nMod)), 12)
icc_lv <- rep(c(rep(icc_lv[1], nRep*nMod), rep(icc_lv[2], nRep*nMod)), 36)
## Force these vectors to be column vectors
ss_l1 <- matrix(ss_l1, ncol=1)
ss_l2 <- matrix(ss_l2, ncol=1)
icc_ov <- matrix(icc_ov, ncol=1)
icc_lv <- matrix(icc_lv, ncol=1)
## Add the labels to the results data frame
sim_results <- sim_results[order(sim_results$Condition),]
sim_results <- cbind(sim_results, ss_l1, ss_l2, icc_ov, icc_lv)
## Force the conditions to be factors
sim_results$ss_l1 <- as.factor(sim_results$ss_l1)
sim_results$ss_l2 <- as.factor(sim_results$ss_l2)
sim_results$icc_ov <- as.factor(sim_results$icc_ov)
sim_results$icc_lv <- as.factor(sim_results$icc_lv)
sim_results$Model <- factor(sim_results$Model, levels = c('C','M1','M2','M12'), ordered = T)
```

## ROC Analysis Labels

Make coding of variables/model specifications for the ROC analyses.
The coding of the variables is in order to get the correct specifications labeled for the ROC analyses to come. 
The coding is as follows:

1. C = correct model specification versus any misspecification (Model C vs. M1, M2, M12)
2. CvM1 = when only the level-1 model is misspecified (Model C vs. M1)
2. CvM2 = when only the level-2 model is misspecified (Model C vs. M2)

```{r}
## Need to make codes for the ROC analyses outcomes
# first, C vs. M1,M2,M12 - Perfect specification
sim_results$C <- ifelse(sim_results$Model == 'C', 1, 0)
table(sim_results$C)
# second, C vs. M1|M12- correct level 1 model
sim_results$CvM1 <- ifelse(sim_results$Model == 'C', 1, 0)
sim_results$CvM1[sim_results$Model == "M2" | sim_results$Model == "M12"] <- NA
table(sim_results$CvM1)
# third, C vs. M2|M12- correct level 2 model
sim_results$CvM2 <- ifelse(sim_results$Model == 'C', 1, 0)
sim_results$CvM2[sim_results$Model == "M1" | sim_results$Model == "M12"] <- NA
table(sim_results$CvM2)
```

# Introduction to ROC Analysis

ROC stands for Receiver Operating Characteristic.
ROC analysis aims to detect the presense of signals in data by looking at how the ability to classify an outcome (usually binary) based on a continuous or ordinal indicator.
ROC analyses was orginally used in wartime to help detect the presence of radar signals.
However, now ROC analysis is used in many areas including medical and psychology research.
It is commonly used as a tool to help make decisions about what tools or methods help classify objects or individuals into specific groups.

In R, a package called pROC (Robin et al., 2011) was built that greatly enhancing the flexibility of using R for ROC analysis.
For example, aside from just being able to conduct ROC analysis, one can compute confidences for this curve and conduct specific statistical tests comparing AUCs from the same data.

For the ROC analyses, we conducted them in pieces to build more and more fine grained information about the classification quality of fit indices for detecting a simple type of misspecification.
For misspecification, we broke up the ROC analyses into three major chunks.

  1. Detecting any type of misspecification (i.e., C vs. M1-M2-M12),
  2. Detecting misspecified level-1 model (i.e., C vs. M1), and
  3. Detecting misspecified level-2 model (i.e., C vs. M2).

Within each of these major chunks of analyses, we furhter investigated whether classification of correctly specified models was depended upon estimator, level-1 sample size, or level-2 sample size.
There are intitally be MANY ROC curve figures and over 1200 ROC analyses. 


Setting up the objects to store the individual results so that we can use them all for the figures.
First, we run over each condition separately then go into the conditional ROC analyses.

```{r}
fit_roc <- fit_roc_smooth <- list()
roc_summary <- as.data.frame(matrix(0,ncol=13, nrow=5*3*4*4*5))
colnames(roc_summary) <- c('Classification','Index', 'Estimator', 'Level-2 SS', 
                           'Level-1 SS', 'AUC',
                           'partial-AUC','Smoothed-AUC', 'Threshold',
                           'Specificity','Sensitivity', 'Num-C', 'Num-Mis')
roc_summary_gen <- as.data.frame(matrix(0,ncol=8, nrow=5)*3)
colnames(roc_summary_gen) <- c('Classification','Index', 'AUC',
                           'partial-AUC','Smoothed-AUC', 'Optimal-Threshold',
                           'Specificity','Sensitivity')
# Defining iterators
CLASS <- c('C', 'CvM1','CvM2')
INDEX <- c('CFI', 'TLI', 'RMSEA', 'SRMRW', 'SRMRB')
EST <- c('ALL','MLR', 'ULSMV', 'WLSMV')
SS_L1 <- c('ALL', 5, 10, 30)
SS_L2 <- c('ALL', 30, 50, 100, 200)
## Subset to the usable cases
sim_results <- filter(sim_results, Converge == 1 & Admissible == 1)
```

# ROC Analyses

## Detecting any type of misspecification

### General overview over all conditions

```{r roc-any-gen, message=FALSE, warning=FALSE}
ig <- 1 ## counter for roc_summary
j <- 1 ## Which class?
for(index in INDEX){
    ## Print out which iteration so we know what we am looking at
    cat('\n\nROC Analysis in')
    cat('\nIndex:\t', index)
    cat('\nClassification:\t', CLASS[j])
    ## Set up iteration key
    key <- paste0(index,'.',CLASS[j])
    ## Create formula
    model <- as.formula(paste0(CLASS[j], '~', index))
    ## Fit ROC curve
    fit_roc[[key]] <-  roc(model, data=sim_results, quiet=TRUE,
                           plot=TRUE, ci=TRUE, print.auc=TRUE)
    ## Create a plot of "smoothed" curve for plotting
    fit_roc_smooth[[key]] <-  smooth(roc(model, data=sim_results))
    ## Compute partial AUC for specificity .8-1
    p.auc <- auc(fit_roc[[key]], partial.auc = c(1,.8),
                 partial.auc.focus = 'sp', partial.auc.correct = T)
    ## get summary info
    roc_summary_gen[ig, 2] <- index
    roc_summary_gen[ig, 1] <- CLASS[j]
    roc_summary_gen[ig, 3] <- fit_roc[[key]]$auc ## total AUC
    roc_summary_gen[ig, 4] <- p.auc ## corrected partial AUC (.5 is no discrimination)
    roc_summary_gen[ig, 5] <- fit_roc_smooth[[key]]$auc ## smoothed AUC
    roc_summary_gen[ig, 6:8] <- coords(fit_roc[[key]], "best", 
                                   ret=c("threshold", "specificity", 'sensitivity'),
                                   transpose=TRUE)
    ## print summary
    cat('\n\nSummary of ROC:\n')
    print(roc_summary_gen[ig, ])
    ## add to summary iterator
    ig <- ig + 1
} ## End loop round index
kable(roc_summary_gen[1:5,], format = 'html', digits=3) %>%
  kable_styling(full_width = T)
print(xtable(roc_summary_gen[1:5,c(2:3,6:8)], digits = 3), booktabs=T,include.rownames = F)
```

### More fine grained information within/across conditions

```{r roc-any, message=FALSE, warning=FALSE}
i <- 1 ## counter for roc_summary
j <- 1 ## Which class?
for(index in INDEX){
  for(est in EST){
    for(s2 in SS_L2){
      for(s1 in SS_L1){
    ## Print out which iteration so we know what we are looking at
    #cat('\n\nROC Analysis in')
    #cat('\nIndex:\t', index)
    #cat('\nClassification:\t', CLASS[j])
    #cat('\nEstimation Method:\t', est)
    #cat('\nLevel-2 Sample Size:\t', s2)
    #cat('\nLevel-1 Sample Size:\t', s1)
    ## Set up iteration key
    key <- paste0(index,'.',CLASS[j],'.',est,'.', s2,'.',s1)
    # Subset data as  needed
    if(est == 'ALL' & s2 == 'ALL' & s1 == 'ALL') mydata <- sim_results
    if(est != 'ALL' & s2 == 'ALL' & s1 == 'ALL'){
      mydata <- filter(sim_results, Estimator == est)
    }
    if(est == 'ALL' & s2 != 'ALL' & s1 == 'ALL'){
      mydata <- filter(sim_results, ss_l2 == s2)
    }
    if(est == 'ALL' & s2 == 'ALL' & s1 != 'ALL'){
      mydata <- filter(sim_results, ss_l1 == s1)
    }
    if(est != 'ALL' & s2 != 'ALL' & s1 == 'ALL'){
      mydata <- filter(sim_results, Estimator == est, ss_l2 == s2)
    }
    if(est != 'ALL' & s2 == 'ALL' & s1 != 'ALL'){
      mydata <- filter(sim_results, Estimator == est, ss_l1 == s1)
    }
    if(est == 'ALL' & s2 != 'ALL' & s1 != 'ALL'){
      mydata <- filter(sim_results, ss_l2 == s2, ss_l1 == s1)
    }
    if(est != 'ALL' & s2 != 'ALL' & s1 != 'ALL'){
      mydata <- filter(sim_results, Estimator == est, ss_l2 == s2, ss_l1 == s1)
    }
    ## Create formula
    model <- as.formula(paste0(CLASS[j], '~', index))
    ## Fit ROC curve
    fit_roc[[key]] <-  roc(model, data=mydata, quiet=T,
                           plot =F, ci=TRUE, print.auc=TRUE)
    ## Create a plot of "smoothed" curve for plotting
    fit_roc_smooth[[key]] <-  smooth(roc(model, data=mydata))
    ## Compute partial AUC for specificity .8-1
    p.auc <- auc(fit_roc[[key]], partial.auc = c(1,.8),
                 partial.auc.focus = 'sp', partial.auc.correct = T)
    ## get summary info
    roc_summary[i, 2] <- index
    roc_summary[i, 1] <- CLASS[j]
    roc_summary[i, 3] <- est ##estimator
    roc_summary[i, 4] <- s2 ## level-2 sample size
    roc_summary[i, 5] <- s1 ## level-1 sample size
    roc_summary[i, 6] <- fit_roc[[key]]$auc ## total AUC
    roc_summary[i, 7] <- p.auc ## corrected partial AUC (.5 is no discrimination)
    roc_summary[i, 8] <- fit_roc_smooth[[key]]$auc ## smoothed AUC
    roc_summary[i, 9:11] <- coords(fit_roc[[key]], "best", 
                                   ret=c("threshold", "specificity", 'sensitivity'),
                                   transpose=TRUE)
    
    ## add number of C and number of miss models in analysis
    n.C <- nrow(mydata[ mydata[, CLASS[j]] == 1, ])
    n.M <- nrow(mydata[ mydata[, CLASS[j]] == 0, ])
    roc_summary[i, 12] <- n.C
    roc_summary[i, 13] <- n.M
    
    ## print summary
    #cat('\n\nSummary of ROC:\n')
    #print(roc_summary[i, ])
    ## add to summary iterator
    i <- i + 1
      } ## end loop around ss l1
    } ## End loop around ss l2
  } ## End loop around estimator
} ## End loop round index
kable(roc_summary[1:400, ], format = 'html', digits=3) %>%
  kable_styling(full_width = T)
```

## Detecting Misspecification at Level-1

### General overview over all conditions

```{r roc-l1-gen, message=FALSE, warning=FALSE}
j <- 2 ## Which class?
for(index in INDEX){
    ## Print out which iteration so we know what we am looking at
    cat('\n\nROC Analysis in')
    cat('\nIndex:\t', index)
    cat('\nClassification:\t', CLASS[j])
    ## Set up iteration key
    key <- paste0(index,'.',CLASS[j])
    ## Create formula
    model <- as.formula(paste0(CLASS[j], '~', index))
    ## Fit ROC curve
    fit_roc[[key]] <-  roc(model, data=sim_results, quiet=T,
                           plot =TRUE, ci=TRUE, print.auc=TRUE)
    ## Create a plot of "smoothed" curve for plotting
    fit_roc_smooth[[key]] <-  smooth(roc(model, data=sim_results))
    ## Compute partial AUC for specificity .8-1
    p.auc <- auc(fit_roc[[key]], partial.auc = c(1,.8),
                 partial.auc.focus = 'sp', partial.auc.correct = T)
    ## get summary info
    roc_summary_gen[ig, 2] <- index
    roc_summary_gen[ig, 1] <- CLASS[j]
    roc_summary_gen[ig, 3] <- fit_roc[[key]]$auc ## total AUC
    roc_summary_gen[ig, 4] <- p.auc ## corrected partial AUC (.5 is no discrimination)
    roc_summary_gen[ig, 5] <- fit_roc_smooth[[key]]$auc ## smoothed AUC
    roc_summary_gen[ig, 6:8] <- coords(fit_roc[[key]], "best", 
                                   ret=c("threshold", "specificity", 'sensitivity'),
                                   transpose=TRUE)
    ## print summary
    cat('\n\nSummary of ROC:\n')
    print(roc_summary_gen[ig, ])
    ## add to summary iterator
    ig <- ig + 1
} ## End loop round index
kable(roc_summary_gen[1:5,], format = 'html', digits=3) %>%
  kable_styling(full_width = T)
print(xtable(roc_summary_gen[1:5,c(2:3,6:8)], digits = 3), booktabs=T,include.rownames = F)
```

### More fine grained information within/across conditions

```{r roc-l1, message=FALSE, warning=FALSE}
i <- 401
j <- 2 ## Which class?
for(index in INDEX){
  for(est in EST){
    for(s2 in SS_L2){
      for(s1 in SS_L1){
    ## Print out which iteration so we know what we are looking at
    #cat('\n\nROC Analysis in')
    #cat('\nIndex:\t', index)
    #cat('\nClassification:\t', CLASS[j])
    #cat('\nEstimation Method:\t', est)
    #cat('\nLevel-2 Sample Size:\t', s2)
    #cat('\nLevel-1 Sample Size:\t', s1)
    ## Set up iteration key
    key <- paste0(index,'.',CLASS[j],'.',est,'.', s2,'.',s1)
    # Subset data as  needed
    if(est == 'ALL' & s2 == 'ALL' & s1 == 'ALL') mydata <- sim_results
    if(est != 'ALL' & s2 == 'ALL' & s1 == 'ALL'){
      mydata <- filter(sim_results, Estimator == est)
    }
    if(est == 'ALL' & s2 != 'ALL' & s1 == 'ALL'){
      mydata <- filter(sim_results, ss_l2 == s2)
    }
    if(est == 'ALL' & s2 == 'ALL' & s1 != 'ALL'){
      mydata <- filter(sim_results, ss_l1 == s1)
    }
    if(est != 'ALL' & s2 != 'ALL' & s1 == 'ALL'){
      mydata <- filter(sim_results, Estimator == est, ss_l2 == s2)
    }
    if(est != 'ALL' & s2 == 'ALL' & s1 != 'ALL'){
      mydata <- filter(sim_results, Estimator == est, ss_l1 == s1)
    }
    if(est == 'ALL' & s2 != 'ALL' & s1 != 'ALL'){
      mydata <- filter(sim_results, ss_l2 == s2, ss_l1 == s1)
    }
    if(est != 'ALL' & s2 != 'ALL' & s1 != 'ALL'){
      mydata <- filter(sim_results, Estimator == est, ss_l2 == s2, ss_l1 == s1)
    }
    ## Create formula
    model <- as.formula(paste0(CLASS[j], '~', index))
    ## Fit ROC curve
    fit_roc[[key]] <-  roc(model, data=mydata,quiet=T,
                           plot =F, ci=TRUE, print.auc=TRUE)
    ## Create a plot of "smoothed" curve for plotting
    fit_roc_smooth[[key]] <-  tryCatch(smooth(roc(model, data=mydata)),
                                       error = function(e) NA)
                                      
    ## Compute partial AUC for specificity .8-1
    p.auc <- auc(fit_roc[[key]], partial.auc = c(1,.8),
                 partial.auc.focus = 'sp', partial.auc.correct = T)
    ## get summary info
    roc_summary[i, 2] <- index
    roc_summary[i, 1] <- CLASS[j]
    roc_summary[i, 3] <- est ##estimator
    roc_summary[i, 4] <- s2 ## level-2 sample size
    roc_summary[i, 5] <- s1 ## level-1 sample size
    roc_summary[i, 6] <- fit_roc[[key]]$auc ## total AUC
    roc_summary[i, 7] <- p.auc ## corrected partial AUC (.5 is no discrimination)
    if(is.na(fit_roc_smooth[[key]]) == T){
      roc_summary[i, 8] <- NA
    } else {
      roc_summary[i, 8] <- fit_roc_smooth[[key]]$auc ## smoothed AUC
    }
    roc_summary[i, 9:11] <- coords(fit_roc[[key]], "best", 
                                   ret=c("threshold", "specificity", 'sensitivity'),
                                   transpose=TRUE)
    
    ## add number of C and number of miss models in analysis
    n.C <- nrow(mydata[ mydata[, CLASS[j]] == 1, ])
    n.M <- nrow(mydata[ mydata[, CLASS[j]] == 0, ])
    roc_summary[i, 12] <- n.C
    roc_summary[i, 13] <- n.M
    
    ## print summary
    #cat('\n\nSummary of ROC:\n')
    #print(roc_summary[i, ])
    ## add to summary iterator
    i <- i + 1
      } ## end loop around ss l1
    } ## End loop around ss l2
  } ## End loop around estimator
} ## End loop round index
kable(roc_summary[401:800, ], format = 'html', digits=3) %>%
  kable_styling(full_width = T)
```



## Detecting Misspecification at Level-2

### General overview over all conditions

```{r roc-l2-gen, message=FALSE, warning=FALSE}
j <- 3 ## Which class?
for(index in INDEX){
    ## Print out which iteration so we know what we am looking at
    cat('\n\nROC Analysis in')
    cat('\nIndex:\t', index)
    cat('\nClassification:\t', CLASS[j])
    ## Set up iteration key
    key <- paste0(index,'.',CLASS[j])
    ## Create formula
    model <- as.formula(paste0(CLASS[j], '~', index))
    ## Fit ROC curve
    fit_roc[[key]] <-  roc(model, data=sim_results,quiet=T,
                           plot =TRUE, ci=TRUE, print.auc=TRUE)
    ## Create a plot of "smoothed" curve for plotting
    fit_roc_smooth[[key]] <-  smooth(roc(model, data=sim_results))
    ## Compute partial AUC for specificity .8-1
    p.auc <- auc(fit_roc[[key]], partial.auc = c(1,.8),
                 partial.auc.focus = 'sp', partial.auc.correct = T)
    ## get summary info
    roc_summary_gen[ig, 2] <- index
    roc_summary_gen[ig, 1] <- CLASS[j]
    roc_summary_gen[ig, 3] <- fit_roc[[key]]$auc ## total AUC
    roc_summary_gen[ig, 4] <- p.auc ## corrected partial AUC (.5 is no discrimination)
    roc_summary_gen[ig, 5] <- fit_roc_smooth[[key]]$auc ## smoothed AUC
    roc_summary_gen[ig, 6:8] <- coords(fit_roc[[key]], "best", 
                                   ret=c("threshold", "specificity", 'sensitivity'),
                                   transpose=TRUE)
    ## print summary
    cat('\n\nSummary of ROC:\n')
    print(roc_summary_gen[ig, ])
    ## add to summary iterator
    ig <- ig + 1
} ## End loop round index
kable(roc_summary_gen[11:15,], format = 'html', digits=3) %>%
  kable_styling(full_width = T)
print(xtable(roc_summary_gen[11:15,c(2:3,6:8)], digits = 3), booktabs=T,include.rownames = F)
```

### More fine grained information within/across conditions

```{r roc-l2, message=FALSE, warning=FALSE}
j <- 3 ## Which class?
for(index in INDEX){
  for(est in EST){
    for(s2 in SS_L2){
      for(s1 in SS_L1){
    ## Print out which iteration so we know what we are looking at
    #cat('\n\nROC Analysis in')
    #cat('\nIndex:\t', index)
    #cat('\nClassification:\t', CLASS[j])
    #cat('\nEstimation Method:\t', est)
    #cat('\nLevel-2 Sample Size:\t', s2)
    #cat('\nLevel-1 Sample Size:\t', s1)
    ## Set up iteration key
    key <- paste0(index,'.',CLASS[j],'.',est,'.', s2,'.',s1)
    # Subset data as  needed
    if(est == 'ALL' & s2 == 'ALL' & s1 == 'ALL') mydata <- sim_results
    if(est != 'ALL' & s2 == 'ALL' & s1 == 'ALL'){
      mydata <- filter(sim_results, Estimator == est)
    }
    if(est == 'ALL' & s2 != 'ALL' & s1 == 'ALL'){
      mydata <- filter(sim_results, ss_l2 == s2)
    }
    if(est == 'ALL' & s2 == 'ALL' & s1 != 'ALL'){
      mydata <- filter(sim_results, ss_l1 == s1)
    }
    if(est != 'ALL' & s2 != 'ALL' & s1 == 'ALL'){
      mydata <- filter(sim_results, Estimator == est, ss_l2 == s2)
    }
    if(est != 'ALL' & s2 == 'ALL' & s1 != 'ALL'){
      mydata <- filter(sim_results, Estimator == est, ss_l1 == s1)
    }
    if(est == 'ALL' & s2 != 'ALL' & s1 != 'ALL'){
      mydata <- filter(sim_results, ss_l2 == s2, ss_l1 == s1)
    }
    if(est != 'ALL' & s2 != 'ALL' & s1 != 'ALL'){
      mydata <- filter(sim_results, Estimator == est, ss_l2 == s2, ss_l1 == s1)
    }
    ## Create formula
    model <- as.formula(paste0(CLASS[j], '~', index))
    ## Fit ROC curve
    fit_roc[[key]] <-  roc(model, data=mydata, quiet=T,
                           plot =F, ci=TRUE, print.auc=TRUE)
    ## Create a plot of "smoothed" curve for plotting
    fit_roc_smooth[[key]] <-  smooth(roc(model, data=mydata))
    ## Compute partial AUC for specificity .8-1
    p.auc <- auc(fit_roc[[key]], partial.auc = c(1,.8),
                 partial.auc.focus = 'sp', partial.auc.correct = T)
    ## get summary info
    roc_summary[i, 2] <- index
    roc_summary[i, 1] <- CLASS[j]
    roc_summary[i, 3] <- est ##estimator
    roc_summary[i, 4] <- s2 ## level-2 sample size
    roc_summary[i, 5] <- s1 ## level-1 sample size
    roc_summary[i, 6] <- fit_roc[[key]]$auc ## total AUC
    roc_summary[i, 7] <- p.auc ## corrected partial AUC (.5 is no discrimination)
    roc_summary[i, 8] <- fit_roc_smooth[[key]]$auc ## smoothed AUC
    roc_summary[i, 9:11] <- coords(fit_roc[[key]], "best", 
                                   ret=c("threshold", "specificity", 'sensitivity'),
                                   transpose=TRUE)
    
    ## add number of C and number of miss models in analysis
    n.C <- nrow(mydata[ mydata[, CLASS[j]] == 1, ])
    n.M <- nrow(mydata[ mydata[, CLASS[j]] == 0, ])
    roc_summary[i, 12] <- n.C
    roc_summary[i, 13] <- n.M
    
    ## print summary
    #cat('\n\nSummary of ROC:\n')
    #print(roc_summary[i, ])
    ## add to summary iterator
    i <- i + 1
      } ## end loop around ss l1
    } ## End loop around ss l2
  } ## End loop around estimator
} ## End loop round index
kable(roc_summary[801:1200, ], format = 'html', digits=3) %>%
  kable_styling(full_width = T)
```

## Summarizing the Results

So, I need to parse down 1200 rows of information into somethingthat can fit into a single page table.
The above (and very large tables) are condensed to only include the AUC and optimal threshold.
The remaining information is left here for reference.

### Detecting Any Misspecification

```{r roc-sum}
c <- filter(roc_summary, Classification == "C", `Level-2 SS` != 'ALL', `Level-1 SS` == 'ALL')
# Next make the columns the estimator factor
c1 <- cbind(c[ c$Estimator == 'MLR', c(2,4,6,9:11)],
            c[ c$Estimator == 'ULSMV', c(6,9:11)],
            c[ c$Estimator == 'WLSMV', c(6,9:11)])
kable(c1, format = 'html',digits=3, row.names = F) %>%
  kable_styling(full_width = T) %>%
  add_header_above(c(' '=2, 'MLR'=4, 'USLMV'=4, 'WLSMV'=4))
c1 <- cbind(c[ c$Estimator == 'MLR', c(2,4,6,9)],
            c[ c$Estimator == 'ULSMV', c(6,9)],
            c[ c$Estimator == 'WLSMV', c(6,9)])
print(xtable(c1, digits = 3), booktabs=T,include.rownames = F)
```

### Detecting Misspecification at level-1


```{r roc-sum-l1}
c <- filter(roc_summary, Classification == "CvM1", `Level-2 SS` != 'ALL', `Level-1 SS` == 'ALL')
# Next make the columns the estimator factor
c1 <- cbind(c[ c$Estimator == 'MLR', c(2,4,6,9:11)],
            c[ c$Estimator == 'ULSMV', c(6,9:11)],
            c[ c$Estimator == 'WLSMV', c(6,9:11)])
kable(c1, format = 'html',digits=3, row.names = F) %>%
  kable_styling(full_width = T) %>%
  add_header_above(c(' '=2, 'MLR'=4, 'USLMV'=4, 'WLSMV'=4))
c1 <- cbind(c[ c$Estimator == 'MLR', c(2,4,6,9)],
            c[ c$Estimator == 'ULSMV', c(6,9)],
            c[ c$Estimator == 'WLSMV', c(6,9)])
print(xtable(c1, digits = 3), booktabs=T,include.rownames = F)
```

### Detecting Misspecification at level-2


```{r roc-sum-l2}
c <- filter(roc_summary, Classification == "CvM2", `Level-2 SS` != 'ALL', `Level-1 SS` == 'ALL')
# Next make the columns the estimator factor
c1 <- cbind(c[ c$Estimator == 'MLR', c(2,4,6,9:11)],
            c[ c$Estimator == 'ULSMV', c(6,9:11)],
            c[ c$Estimator == 'WLSMV', c(6,9:11)])
kable(c1, format = 'html',digits=3, row.names = F) %>%
  kable_styling(full_width = T) %>%
  add_header_above(c(' '=2, 'MLR'=4, 'USLMV'=4, 'WLSMV'=4))
c1 <- cbind(c[ c$Estimator == 'MLR', c(2,4,6,9)],
            c[ c$Estimator == 'ULSMV', c(6,9)],
            c[ c$Estimator == 'WLSMV', c(6,9)])
print(xtable(c1, digits = 3), booktabs=T,include.rownames = F)
```


# ROC Curves

## First extract the data

```{r roc-data-extract}
roc_smooth_data <- as.data.frame(matrix(0,ncol=7, nrow=514*(3*4*5*5)))
colnames(roc_smooth_data) <- c('Index', 'Classification', 'Estimator','Level-2 SS', 'AUC', 'Sensitivity', 'Specificity')
i <- 1
j <- 514
for(index in INDEX){
  for(est in EST){
    for(class in CLASS){
    for(s2 in SS_L2){
    ## Set up iteration key
    key <- paste0(index,'.',class,'.',est,'.', s2,'.ALL')
      ## update extracted data
      roc_smooth_data[i:j, 1] <- index
      roc_smooth_data[i:j, 2] <- class
      roc_smooth_data[i:j, 3] <- est
      roc_smooth_data[i:j, 4] <- s2
      ## extract smooth fit object
      fit <- fit_roc_smooth[[key]]
      if(is.null(fit) == T){
        ## update sen,spec, and auc
        roc_smooth_data[i:j, 5] <- NA
        roc_smooth_data[i:j, 6] <- NA
        roc_smooth_data[i:j, 7] <- NA
      } else {
        ## update sen,spec, and auc
        roc_smooth_data[i:j, 5] <- fit$auc
        roc_smooth_data[i:j, 6] <- fit$sensitivities
        roc_smooth_data[i:j, 7] <- fit$specificities
      }
      
      ## update iterators
      i <- i + 514
      j <- j + 514
    }
  }
}}
## Forcing factor orders
roc_smooth_data$Index <- factor(
  roc_smooth_data$Index, ordered = T,
  levels=c('CFI', 'TLI', 'RMSEA', 'SRMRW', 'SRMRB'))
roc_smooth_data$Classification <- factor(
  roc_smooth_data$Classification,
  levels=c('C','CvM1','CvM2'),
  labels=c('Any Mis.', 'Level-1 Mis.', 'Level-2 Mis.'),
  ordered = T
)
roc_smooth_data$Estimator <- as.factor(roc_smooth_data$Estimator)
roc_smooth_data$`Level-2 SS` <- factor(roc_smooth_data$`Level-2 SS`,
                                       levels=c('ALL','30','50', '100', '200'),
                                       ordered = T)
```


## Plot by Misspecification and Estimation Method

```{r figures}
subdata <- filter(roc_smooth_data, `Level-2 SS`=='ALL', Estimator!='ALL')
p <- ggplot(subdata, aes(x = Specificity, y=Sensitivity, group = Index)) +
  geom_line(aes(linetype=Index, color=Index))+
  facet_grid(Estimator~Classification) +
  scale_x_reverse() +
  scale_color_brewer(palette="Set1") +
  guides(color=guide_legend(title="Fit Index"),
         linetype=guide_legend(title="Fit Index")) +
  geom_abline(intercept = 1, slope = 1, color='dimgray' )
p
if(save.fig == T) ggsave('roc_plot_mis_est.pdf', plot = p, height = 6,width = 9,units = 'in')
```

## Plot by Misspecification and Level-2 Sample Size

```{r figures-1}
subdata <- filter(roc_smooth_data, `Level-2 SS`!='ALL', Estimator=='ALL')
p <- ggplot(subdata, aes(x = Specificity, y=Sensitivity, group = Index)) +
  geom_line(aes(linetype=Index, color=Index))+
  facet_grid(`Level-2 SS` ~Classification) +
  scale_x_reverse() +
  scale_color_brewer(palette="Set1") +
  guides(color=guide_legend(title="Fit Index"),
         linetype=guide_legend(title="Fit Index"))+
  geom_abline(intercept = 1, slope = 1, color='dimgray' )
p
if(save.fig == T) ggsave('roc_plot_mis_n2.pdf', plot = p, height = 6,width = 9, units = 'in')
```

## Figures of Subconditions and Smaller Plots for Exporting

### Figures by Classification Outcome

```{r subfigs-class}
subdata <- filter(roc_smooth_data, `Level-2 SS`=='ALL',  Estimator == "ALL")
p <- ggplot(subdata, aes(x = Specificity, y=Sensitivity, group = Index)) +
  geom_line(aes(linetype=Index, color=Index))+
  facet_grid(.~Classification) +
  scale_x_reverse() +
  scale_color_brewer(palette="Set1") +
  guides(color=guide_legend(title="Fit Index"),
         linetype=guide_legend(title="Fit Index"))+
  geom_abline(intercept = 1, slope = 1, color='dimgray' )
p
if(save.fig == T) ggsave('roc_class_all.pdf', plot = p, height = 4, width = 9, units = 'in')
subdata <- filter(roc_smooth_data, `Level-2 SS`=='ALL', Estimator == "MLR")
p <- ggplot(subdata, aes(x = Specificity, y=Sensitivity, group = Index)) +
  geom_line(aes(linetype=Index, color=Index))+
  facet_grid(.~Classification) +
  scale_x_reverse() +
  scale_color_brewer(palette="Set1") +
  guides(color=guide_legend(title="Fit Index"),
         linetype=guide_legend(title="Fit Index"))+
  geom_abline(intercept = 1, slope = 1, color='dimgray' )
p
if(save.fig == T) ggsave('roc_class_mlr.pdf', plot = p, height = 4,width = 9,units = 'in')
subdata <- filter(roc_smooth_data, `Level-2 SS`=='ALL', Estimator == "ULSMV")
p <- ggplot(subdata, aes(x = Specificity, y=Sensitivity, group = Index)) +
  geom_line(aes(linetype=Index, color=Index))+
  facet_grid(.~Classification) +
  scale_x_reverse() +
  scale_color_brewer(palette="Set1") +
  guides(color=guide_legend(title="Fit Index"),
         linetype=guide_legend(title="Fit Index"))+
  geom_abline(intercept = 1, slope = 1, color='dimgray' )
p
if(save.fig == T) ggsave('roc_class_ulsmv.pdf', plot = p, height = 4,width = 9,units = 'in')
subdata <- filter(roc_smooth_data,`Level-2 SS`=='ALL',  Estimator == "WLSMV")
p <- ggplot(subdata, aes(x = Specificity, y=Sensitivity, group = Index)) +
  geom_line(aes(linetype=Index, color=Index))+
  facet_grid(.~Classification) +
  scale_x_reverse() +
  scale_color_brewer(palette="Set1") +
  guides(color=guide_legend(title="Fit Index"),
         linetype=guide_legend(title="Fit Index"))+
  geom_abline(intercept = 1, slope = 1, color='dimgray' )
p
if(save.fig == T) ggsave('roc_class_wlsmv.pdf', plot = p, height = 4,width = 9,units = 'in')
```


### Figures by Estimation Method

```{r subfigs-est}
subdata <- filter(roc_smooth_data, `Level-2 SS`=='ALL', Estimator!='ALL',
                  Classification == "Any Mis.")
p <- ggplot(subdata, aes(x = Specificity, y=Sensitivity, group = Index)) +
  geom_line(aes(linetype=Index, color=Index))+
  facet_grid(.~Estimator) +
  scale_x_reverse() +
  scale_color_brewer(palette="Set1") +
  guides(color=guide_legend(title="Fit Index"),
         linetype=guide_legend(title="Fit Index"))+
  geom_abline(intercept = 1, slope = 1, color='dimgray' )
p
if(save.fig == T) ggsave('roc_est_c.pdf', plot = p, height = 4,width = 9,units = 'in')
subdata <- filter(roc_smooth_data, `Level-2 SS`=='ALL', Estimator!='ALL',
                  Classification == "Level-1 Mis.")
p <- ggplot(subdata, aes(x = Specificity, y=Sensitivity, group = Index)) +
  geom_line(aes(linetype=Index, color=Index))+
  facet_grid(.~Estimator) +
  scale_x_reverse() +
  scale_color_brewer(palette="Set1") +
  guides(color=guide_legend(title="Fit Index"),
         linetype=guide_legend(title="Fit Index"))+
  geom_abline(intercept = 1, slope = 1, color='dimgray' )
p
if(save.fig == T) ggsave('roc_est_cl1.pdf', plot = p, height = 4,width = 9,units = 'in')
subdata <- filter(roc_smooth_data,`Level-2 SS`=='ALL', Estimator!='ALL',
                  Classification == "Level-2 Mis.")
p <- ggplot(subdata, aes(x = Specificity, y=Sensitivity, group = Index)) +
  geom_line(aes(linetype=Index, color=Index))+
  facet_grid(.~Estimator) +
  scale_x_reverse() +
  scale_color_brewer(palette="Set1") +
  guides(color=guide_legend(title="Fit Index"),
         linetype=guide_legend(title="Fit Index"))+
  geom_abline(intercept = 1, slope = 1, color='dimgray' )
p
if(save.fig == T) ggsave('roc_est_cl2.pdf', plot = p, height = 4,width = 9,units = 'in')
```


### Figures by Level-2 Sample Size

```{r subfigs-est-l2}
subdata <- filter(roc_smooth_data, Estimator=='ALL', Classification == "Any Mis.",
                  `Level-2 SS`!='ALL')
p <- ggplot(subdata, aes(x = Specificity, y=Sensitivity, group = Index)) +
  geom_line(aes(linetype=Index, color=Index))+
  facet_grid(.~`Level-2 SS`) +
  scale_x_reverse() +
  scale_color_brewer(palette="Set1") +
  guides(color=guide_legend(title="Fit Index"),
         linetype=guide_legend(title="Fit Index"))+
  geom_abline(intercept = 1, slope = 1, color='dimgray')
p
if(save.fig == T) ggsave('roc_n2_c.pdf', plot = p, height = 4,width = 9,units = 'in')
subdata <- filter(roc_smooth_data, `Level-2 SS`!='ALL', Estimator=='ALL',
                  Classification == "Level-1 Mis.")
p <- ggplot(subdata, aes(x = Specificity, y=Sensitivity, group = Index)) +
  geom_line(aes(linetype=Index, color=Index))+
  facet_grid(.~`Level-2 SS`) +
  scale_x_reverse() +
  scale_color_brewer(palette="Set1") +
  guides(color=guide_legend(title="Fit Index"),
         linetype=guide_legend(title="Fit Index"))+
  geom_abline(intercept = 1, slope = 1, color='dimgray' )
p
if(save.fig == T) ggsave('roc_n2_cl1.pdf', plot = p, height = 4,width = 9,units = 'in')
subdata <- filter(roc_smooth_data,`Level-2 SS`!='ALL', Estimator=='ALL',  Classification == "Level-2 Mis.")
p <- ggplot(subdata, aes(x = Specificity, y=Sensitivity, group = Index)) +
  geom_line(aes(linetype=Index, color=Index))+
  facet_grid(.~`Level-2 SS`) +
  scale_x_reverse() +
  scale_color_brewer(palette="Set1") +
  guides(color=guide_legend(title="Fit Index"),
         linetype=guide_legend(title="Fit Index"))+
  geom_abline(intercept = 1, slope = 1, color='dimgray' )
p
if(save.fig == T) ggsave('roc_n2_cl2.pdf', plot = p, height = 4,width = 9,units = 'in')
```